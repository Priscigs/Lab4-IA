{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad768118-449c-43c9-9431-470ae1372178",
   "metadata": {},
   "source": [
    "# Task 1, Task 2 y Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e315a3b-3cf9-4709-ac6d-72470cf6b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf03f04-6fd3-4c9d-9c4a-24dddb1bc744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [-0.33706938  0.24909504]\n"
     ]
    }
   ],
   "source": [
    "# Leer archivo CSV\n",
    "data = np.genfromtxt('framingham.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# Seleccionar columnas 0 y 3\n",
    "X = data[:, 3]  # Fumador\n",
    "y = data[:, 0]  # Sufre o no sufre un paro cardíaco\n",
    "\n",
    "# Función sigmoide\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Función de regresión logística por descenso de gradiente\n",
    "def logistic_regression(X, y, alpha, num_iters):\n",
    "    # Añadir columna de unos a X\n",
    "    X = np.vstack([np.ones(len(X)), X]).T\n",
    "    \n",
    "    # Inicializar parámetros\n",
    "    theta = np.zeros(2)\n",
    "    \n",
    "    # Descenso de gradiente\n",
    "    for i in range(num_iters):\n",
    "        # Calcular hipótesis\n",
    "        z = np.dot(X, theta)\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # Calcular gradiente y actualizar parámetros\n",
    "        grad = np.dot(X.T, (h - y)) / len(y)\n",
    "        theta -= alpha * grad\n",
    "        \n",
    "    return theta\n",
    "\n",
    "# Ajustar modelo\n",
    "theta = logistic_regression(X, y, 0.01, 1000)\n",
    "\n",
    "# Mostrar parámetros\n",
    "print('theta:', theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02ddcc-5095-4ffd-b079-27e93289fcb4",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666e7d18-c602-4c81-a5ce-da6492496bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor grado del polinomio es: 1\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Definir los grados del polinomio a probar\n",
    "degrees = range(1, 10)\n",
    "\n",
    "# Inicializar la precisión promedio para cada grado del polinomio\n",
    "mean_accs = []\n",
    "\n",
    "# Realizar validación cruzada para cada grado del polinomio\n",
    "for degree in degrees:\n",
    "    accs = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Transformar las variables de entrada con el grado del polinomio actual\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_train_poly = poly.fit_transform(X_train.reshape(-1, 1))\n",
    "        X_test_poly = poly.fit_transform(X_test.reshape(-1, 1))\n",
    "\n",
    "        # Ajustar modelo de regresión logística\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train_poly, y_train)\n",
    "\n",
    "        # Predecir valores y calcular precisión\n",
    "        y_pred = lr.predict(X_test_poly)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        accs.append(acc)\n",
    "\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_accs.append(mean_acc)\n",
    "\n",
    "# Encontrar el grado del polinomio que maximiza la precisión promedio\n",
    "best_degree = degrees[np.argmax(mean_accs)]\n",
    "print('El mejor grado del polinomio es:', best_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e40152-0ddd-40c0-9141-5b0f9fe39dec",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17580ec-12cf-4cca-ac84-1d6bc6738710",
   "metadata": {},
   "source": [
    "1. Después de analizar los datos y ajustar un modelo de regresión logística polinomial utilizando validación cruzada para determinar el grado óptimo del polinomio, encontramos que el grado óptimo del polinomio fue de 1. Esto significa que una relación lineal entre la variable independiente (fumador) y la variable dependiente (sufre o no un paro cardíaco) puede ser suficiente para describir la relación entre las variables.\n",
    "2. Es importante destacar que esto no significa necesariamente que una relación no lineal no exista entre las variables. Es posible que no se hayan medido todas las variables relevantes en el conjunto de datos, lo que podría haber afectado la forma de la relación.\n",
    "3. También es importante tener en cuenta que aunque la relación entre las variables parece ser lineal, esto no implica causalidad. Es posible que otras variables, no incluidas en el conjunto de datos, estén influyendo en la relación observada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
